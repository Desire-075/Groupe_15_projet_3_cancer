PROMPT ENGINEERING DOCUMENTATION:Oversampling
1. Context
In our cervical cancer risk assessment project, we identified a class imbalance in the target variable (Biopsy). To address this issue, we used oversampling via the SMOTE (Synthetic Minority Over-sampling Technique) method.
2. Objective
The objective of this section is to document the prompts used to optimize synthetic data generation and evaluate their impact on model performance.
3. Prompts Used
Prompt before adjustments (general):
"I have an imbalanced dataset for a binary classification problem, with an underrepresented minority class. How can I use SMOTE to balance the classes before training my model?"

Code implemented before adjustments:
from imblearn.over_sampling import SMOTE
smote = SMOTE()
x_train, y_train = smote.fit_resample(X, y)
Issues encountered:
•	Overfitting during training.
•	No control over the k_neighbors parameter.
•	Lack of reproducibility of results.

Prompt before adjustments (clarifying parameters):
"In SMOTE, there is a parameter k_neighbors that controls the number of neighbors used to generate synthetic samples. How does this parameter influence the distribution of generated data? Additionally, random_state allows setting a random seed for reproducibility. What is the best value to choose for these parameters in a binary classification problem?"

ChatGPT response:
•	k_neighbors: Defines the number of neighbors used to generate a new synthetic sample. A high value may lead to over-generalization, while a low value can produce less varied samples. A common value is k_neighbors=3.
•	random_state: Sets a random seed to ensure that results are reproducible across different runs. It is recommended to use a fixed value such as random_state=42 to ensure consistency.

Prompt after adjustments:
"I am working on a binary classification problem with class imbalance. The target variable Biopsy has a low proportion of the minority class. I plan to use SMOTE to balance the classes before training my model. How can I adjust SMOTE parameters (such as k_neighbors and random_state) to avoid overfitting and ensure better generalization of the model? Can you also suggest alternative methods if SMOTE does not work well?"

Code implemented after adjustments:
from imblearn.over_sampling import SMOTE
smote = SMOTE(k_neighbors=3, random_state=42)
x_train, y_train = smote.fit_resample(X, y)

4. Results Generated by ChatGPT
ChatGPT suggested the following adjustments:
•	Use k_neighbors=3 to avoid over-generalization.
•	Set random_state=42 to ensure reproducibility.
•	Compare SMOTE with other techniques like ADASYN (Adaptive Synthetic Sampling) and SMOTE-Tomek.
•	Evaluate the effect of oversampling on model performance using a confusion matrix and an ROC curve.

5. Implementation and Results
Model Evaluation After Oversampling
•	RandomForestClassifier: 100% accuracy in training, 96% in testing.
•	XGBoost: 99% accuracy in testing, better generalization.
•	CatBoost: Final model chosen with good performance.


6. Discussion and Improvements
•	Strengths of the prompt:
o	Explores different oversampling techniques.
o	Helps avoid overfitting by adjusting k_neighbors.
o	Encourages post-oversampling evaluation using relevant metrics.


•	Possible improvements:
1.	Test a more detailed prompt for each alternative
Example of an improved prompt:
"My dataset is imbalanced, with an underrepresented minority class. I am using SMOTE, but I would like to compare this approach with ADASYN and SMOTE-Tomek. Can you explain their differences, advantages, and disadvantages, and suggest which method would be best suited for the following dataset characteristics: [insert dataset details]?"
o	The current adjusted prompt asks for alternative methods to SMOTE but does not go into detail.
o	A better approach would be to write a prompt that specifically compares SMOTE, ADASYN, and SMOTE-Tomek, explaining their advantages and disadvantages based on our dataset.

2.	Automate the comparison of SMOTE parameters
Example of a prompt to generate this code automatically:
"I want to test different values of the k_neighbors parameter in SMOTE to see which yields the best classification performance. Can you provide a script that performs a grid search on values 2, 3, 5, and 7 and compares the impact on model accuracy and F1-score?"
This would help avoid choosing arbitrary parameters and achieve a better balance between generalization and performance.
o	Currently, we have manually set k_neighbors=3 and random_state=42.
o	A better approach would be to use ChatGPT to generate code that tests multiple values of k_neighbors and automatically identifies the best configuration.


7. Conclusion
Using ChatGPT to optimize oversampling helped improve class balance while avoiding overfitting. The methodology could be refined by integrating more experiments and automating the comparison of class balancing methods.





